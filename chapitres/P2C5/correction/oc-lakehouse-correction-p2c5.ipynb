{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1f813d-9d7b-4ce0-be6c-d9a18d2b92d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mini-cycle de maintenance Delta Lake – GreenFarm (Unity Catalog + Volumes)\n",
    "\n",
    "Objectif : reproduire un mini-cycle de maintenance Delta Lake complet.\n",
    "\n",
    "### Étapes\n",
    "1) Créer une table Delta **partitionnée** par `ingest_date` à partir du CSV  \n",
    "2) Simuler une croissance (générer et ajouter des lignes)  \n",
    "3) Observer la fragmentation (`numFiles`, `sizeInBytes`)  \n",
    "4) Lancer `OPTIMIZE` sur les partitions récentes  \n",
    "5) Activer le CDF, faire une mise à jour + insertion, puis lire les changements  \n",
    "6) Tester Time Travel (lire une version antérieure)  \n",
    "7) Lancer `VACUUM` avec une rétention courte (24h) et constater l’effet  \n",
    "\n",
    "✅ À la fin : expliquer ce que vous observez avant/après OPTIMIZE, puis l’intérêt de CDF / Time Travel / VACUUM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd7db5ab-43aa-4c56-99af-c8949f38d3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: /Volumes/workspace/default/oc-lakehouse/sensors_full.csv\nTable: greenfarm.sensors_maintenance\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import time\n",
    "\n",
    "# Paramètres (Unity Catalog + Volumes) - (à adapter si besoin)\n",
    "csv_path = \"/Volumes/workspace/default/oc-lakehouse/sensors_full.csv\"\n",
    "\n",
    "db_name = \"greenfarm\"\n",
    "table_name = \"sensors_maintenance\"\n",
    "full_name = f\"{db_name}.{table_name}\"\n",
    "\n",
    "print(\"CSV:\", csv_path)\n",
    "print(\"Table:\", full_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c74598-fc44-4070-9305-bd85f3dca050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1) Créer une table Delta partitionnée (ingest_date)\n",
    "\n",
    "Ici on **impose le schéma** au chargement du CSV pour éviter les problèmes de type\n",
    "(ex : `sensor_id` lu comme string).\n",
    "\n",
    "On ajoute ensuite `ingest_date` et on écrit une **managed table Unity Catalog**\n",
    "partitionnée par `ingest_date`.\n",
    "\n",
    "**À observer :**\n",
    "- schéma final\n",
    "- `partitionColumns = ['ingest_date']`\n",
    "- entrée dans `DESCRIBE HISTORY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "038ee3cb-b41a-4ba4-82e6-227638a9322b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sensor_id</th><th>humidity</th><th>parcel</th><th>ingest_date</th></tr></thead><tbody><tr><td>1000</td><td>30.9</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1001</td><td>35.0</td><td>West-1</td><td>2026-01-23</td></tr><tr><td>1002</td><td>47.5</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1003</td><td>56.2</td><td>East-2</td><td>2026-01-23</td></tr><tr><td>1004</td><td>54.2</td><td>North-1</td><td>2026-01-23</td></tr><tr><td>1005</td><td>43.5</td><td>South-1</td><td>2026-01-23</td></tr><tr><td>1006</td><td>36.6</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1007</td><td>56.6</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1008</td><td>55.1</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1009</td><td>31.0</td><td>South-2</td><td>2026-01-23</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1000,
         30.9,
         "West-2",
         "2026-01-23"
        ],
        [
         1001,
         35.0,
         "West-1",
         "2026-01-23"
        ],
        [
         1002,
         47.5,
         "East-1",
         "2026-01-23"
        ],
        [
         1003,
         56.2,
         "East-2",
         "2026-01-23"
        ],
        [
         1004,
         54.2,
         "North-1",
         "2026-01-23"
        ],
        [
         1005,
         43.5,
         "South-1",
         "2026-01-23"
        ],
        [
         1006,
         36.6,
         "East-1",
         "2026-01-23"
        ],
        [
         1007,
         56.6,
         "West-2",
         "2026-01-23"
        ],
        [
         1008,
         55.1,
         "East-1",
         "2026-01-23"
        ],
        [
         1009,
         31.0,
         "South-2",
         "2026-01-23"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sensor_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "parcel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6000\nroot\n |-- sensor_id: long (nullable = true)\n |-- humidity: double (nullable = true)\n |-- parcel: string (nullable = true)\n |-- ingest_date: date (nullable = false)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th><th>clusterByAuto</th></tr></thead><tbody><tr><td>delta</td><td>56802398-b2e8-459b-a4bf-d05a1c9c75a7</td><td>workspace.greenfarm.sensors_maintenance</td><td>null</td><td></td><td>2026-01-23T09:52:28.907Z</td><td>2026-01-23T09:52:33.000Z</td><td>List(ingest_date)</td><td>List()</td><td>1</td><td>17337</td><td>Map(delta.parquet.compression.codec -> zstd, delta.enableDeletionVectors -> true)</td><td>3</td><td>7</td><td>List(appendOnly, deletionVectors, invariants)</td><td>Map(numRowsDeletedByDeletionVectors -> 0, numDeletionVectors -> 0)</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta",
         "56802398-b2e8-459b-a4bf-d05a1c9c75a7",
         "workspace.greenfarm.sensors_maintenance",
         null,
         "",
         "2026-01-23T09:52:28.907Z",
         "2026-01-23T09:52:33.000Z",
         [
          "ingest_date"
         ],
         [],
         1,
         17337,
         {
          "delta.enableDeletionVectors": "true",
          "delta.parquet.compression.codec": "zstd"
         },
         3,
         7,
         [
          "appendOnly",
          "deletionVectors",
          "invariants"
         ],
         {
          "numDeletionVectors": 0,
          "numRowsDeletedByDeletionVectors": 0
         },
         false
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "clusteringColumns",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"long\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterByAuto",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>0</td><td>2026-01-23T09:52:33.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [\"ingest_date\"], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}, statsOnLoad -> true)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numRemovedFiles -> 0, numRemovedBytes -> 0, numDeletionVectorsRemoved -> 0, numOutputRows -> 6000, numOutputBytes -> 17337)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "2026-01-23T09:52:33.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[\"ingest_date\"]",
          "properties": "{\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}",
          "statsOnLoad": "true"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         null,
         "WriteSerializable",
         false,
         {
          "numDeletionVectorsRemoved": "0",
          "numFiles": "1",
          "numOutputBytes": "17337",
          "numOutputRows": "6000",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) DB + drop table\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {full_name}\")\n",
    "\n",
    "# 2) Schéma imposé\n",
    "schema = T.StructType([\n",
    "    T.StructField(\"sensor_id\", T.LongType(), True),\n",
    "    T.StructField(\"humidity\", T.DoubleType(), True),\n",
    "    T.StructField(\"parcel\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(csv_path)\n",
    "    .withColumn(\"ingest_date\", F.current_date())\n",
    ")\n",
    "\n",
    "display(df.limit(10))\n",
    "print(\"Rows:\", df.count())\n",
    "df.printSchema()\n",
    "\n",
    "# 3) Écriture Delta partitionnée (UC managed table)\n",
    "(df.write.format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy(\"ingest_date\")\n",
    " .saveAsTable(full_name)\n",
    ")\n",
    "\n",
    "# Vérifications\n",
    "display(spark.sql(f\"DESCRIBE DETAIL {full_name}\"))\n",
    "display(spark.sql(f\"DESCRIBE HISTORY {full_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36200a00-32d0-4e2d-96b5-71b90ba01dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2) Simuler une croissance (génération + append)\n",
    "\n",
    "Comme le CSV d’origine fait ~6 000 lignes, un simple `limit(200000)` ne peut pas produire\n",
    "200 000 lignes (il n’y a pas assez de données).\n",
    "\n",
    "On va donc **dupliquer** le dataset via un `crossJoin(range(multiplier))` pour créer\n",
    "beaucoup de nouvelles lignes, puis les écrire en `append`.\n",
    "\n",
    "Pour créer de la fragmentation :\n",
    "- `repartition(n_files_target)`\n",
    "- `maxRecordsPerFile` bas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e72c791c-9232-49f1-b597-82b56a4ed535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after growth: 306000\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>1</td><td>2026-01-23T09:54:32.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 600, numOutputRows -> 300000, numOutputBytes -> 1650083)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>0</td><td>2026-01-23T09:52:33.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [\"ingest_date\"], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}, statsOnLoad -> true)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numRemovedFiles -> 0, numRemovedBytes -> 0, numDeletionVectorsRemoved -> 0, numOutputRows -> 6000, numOutputBytes -> 17337)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "2026-01-23T09:54:32.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         0,
         "WriteSerializable",
         false,
         {
          "numFiles": "600",
          "numOutputBytes": "1650083",
          "numOutputRows": "300000"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         0,
         "2026-01-23T09:52:33.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[\"ingest_date\"]",
          "properties": "{\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}",
          "statsOnLoad": "true"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         null,
         "WriteSerializable",
         false,
         {
          "numDeletionVectorsRemoved": "0",
          "numFiles": "1",
          "numOutputBytes": "17337",
          "numOutputRows": "6000",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplier = 50        # 6000 * 50 ≈ 300k lignes générées\n",
    "n_files_target = 200   # fragmentation volontaire\n",
    "\n",
    "base = spark.table(full_name)\n",
    "\n",
    "growth = (\n",
    "    base.crossJoin(spark.range(multiplier).withColumnRenamed(\"id\", \"batch_id\"))\n",
    "        # On rend sensor_id unique pour éviter collisions\n",
    "        .withColumn(\"sensor_id\", F.col(\"sensor_id\") + F.col(\"batch_id\") * F.lit(1_000_000))\n",
    "        # On simule des données récentes (partition récente)\n",
    "        .withColumn(\"ingest_date\", F.date_add(F.current_date(), 1))\n",
    "        .drop(\"batch_id\")\n",
    "        .repartition(n_files_target)\n",
    ")\n",
    "\n",
    "(growth.write.format(\"delta\")\n",
    " .mode(\"append\")\n",
    " .option(\"maxRecordsPerFile\", 500)   # plus petit => + de fichiers\n",
    " .saveAsTable(full_name)\n",
    ")\n",
    "\n",
    "print(\"Total rows after growth:\", spark.table(full_name).count())\n",
    "display(spark.sql(f\"DESCRIBE HISTORY {full_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8baf7e9b-4efa-431a-aaa6-597c54cf0bc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3) Observer la fragmentation\n",
    "\n",
    "Sur Databricks Free + Unity Catalog, on observe la fragmentation via `DESCRIBE DETAIL` :\n",
    "- `numFiles` = nombre de fichiers Parquet (indicateur de fragmentation)\n",
    "- `sizeInBytes` = taille totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c33d0c4-e4d3-4256-bb0e-817771b659bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format: delta\npartitionColumns: ['ingest_date']\nnumFiles: 347\nsizeInMB: 1.07\n"
     ]
    }
   ],
   "source": [
    "detail = spark.sql(f\"DESCRIBE DETAIL {full_name}\").collect()[0].asDict()\n",
    "\n",
    "print(\"format:\", detail.get(\"format\"))\n",
    "print(\"partitionColumns:\", detail.get(\"partitionColumns\"))\n",
    "print(\"numFiles:\", detail.get(\"numFiles\"))\n",
    "print(\"sizeInMB:\", round((detail.get(\"sizeInBytes\") or 0) / (1024*1024), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ed9a878-7fcf-46bd-bb2c-43e027eee258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4) OPTIMIZE sur partitions récentes\n",
    "\n",
    "Comme la table est partitionnée sur `ingest_date`, on peut optimiser uniquement les partitions récentes.\n",
    "\n",
    "**À observer :**\n",
    "- `numFiles` diminue après OPTIMIZE\n",
    "- nouvelle entrée dans l’historique (operation = OPTIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc3075e6-e419-45dc-b969-6646fb474466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE OPTIMIZE - numFiles: 347 sizeMB: 1.07\nAFTER OPTIMIZE  - numFiles: 2 sizeMB: 0.36\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>4</td><td>2026-01-23T09:58:22.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>OPTIMIZE</td><td>Map(predicate -> [\"('ingest_date >= 'date_sub('current_date(), 2))\"], auto -> false, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>3</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 346, numRemovedBytes -> 1107230, p25FileSize -> 360923, numDeletionVectorsRemoved -> 0, minFileSize -> 360923, numAddedFiles -> 1, maxFileSize -> 360923, p75FileSize -> 360923, p50FileSize -> 360923, numAddedBytes -> 360923)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>3</td><td>2026-01-23T09:54:44.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>OPTIMIZE</td><td>Map(predicate -> [\"('ingest_date <=> cast(2026-01-24 as date))\"], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 1)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>1</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 128, numRemovedBytes -> 351842, p25FileSize -> 79574, numDeletionVectorsRemoved -> 0, conflictDetectionTimeMs -> 88, minFileSize -> 79574, numAddedFiles -> 1, maxFileSize -> 79574, p75FileSize -> 79574, p50FileSize -> 79574, numAddedBytes -> 79574)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>2</td><td>2026-01-23T09:54:41.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>OPTIMIZE</td><td>Map(predicate -> [\"('ingest_date <=> cast(2026-01-24 as date))\"], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>1</td><td>SnapshotIsolation</td><td>false</td><td>Map(numRemovedFiles -> 128, numRemovedBytes -> 352161, p25FileSize -> 81576, numDeletionVectorsRemoved -> 0, minFileSize -> 81576, numAddedFiles -> 1, maxFileSize -> 81576, p75FileSize -> 81576, p50FileSize -> 81576, numAddedBytes -> 81576)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>1</td><td>2026-01-23T09:54:32.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 600, numOutputRows -> 300000, numOutputBytes -> 1650083)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>0</td><td>2026-01-23T09:52:33.000Z</td><td>252167878869526</td><td>alexandre.bergere@datalex.io</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [\"ingest_date\"], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}, statsOnLoad -> true)</td><td>null</td><td>List(2491241394162189)</td><td>0123-095152-mnd9q50q-v2n</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numRemovedFiles -> 0, numRemovedBytes -> 0, numDeletionVectorsRemoved -> 0, numOutputRows -> 6000, numOutputBytes -> 17337)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         "2026-01-23T09:58:22.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "OPTIMIZE",
         {
          "auto": "false",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[\"('ingest_date >= 'date_sub('current_date(), 2))\"]",
          "zOrderBy": "[]"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         3,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "360923",
          "minFileSize": "360923",
          "numAddedBytes": "360923",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "0",
          "numRemovedBytes": "1107230",
          "numRemovedFiles": "346",
          "p25FileSize": "360923",
          "p50FileSize": "360923",
          "p75FileSize": "360923"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         3,
         "2026-01-23T09:54:44.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "1",
          "clusterBy": "[]",
          "predicate": "[\"('ingest_date <=> cast(2026-01-24 as date))\"]",
          "zOrderBy": "[]"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         1,
         "SnapshotIsolation",
         false,
         {
          "conflictDetectionTimeMs": "88",
          "maxFileSize": "79574",
          "minFileSize": "79574",
          "numAddedBytes": "79574",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "0",
          "numRemovedBytes": "351842",
          "numRemovedFiles": "128",
          "p25FileSize": "79574",
          "p50FileSize": "79574",
          "p75FileSize": "79574"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         2,
         "2026-01-23T09:54:41.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "OPTIMIZE",
         {
          "auto": "true",
          "batchId": "0",
          "clusterBy": "[]",
          "predicate": "[\"('ingest_date <=> cast(2026-01-24 as date))\"]",
          "zOrderBy": "[]"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         1,
         "SnapshotIsolation",
         false,
         {
          "maxFileSize": "81576",
          "minFileSize": "81576",
          "numAddedBytes": "81576",
          "numAddedFiles": "1",
          "numDeletionVectorsRemoved": "0",
          "numRemovedBytes": "352161",
          "numRemovedFiles": "128",
          "p25FileSize": "81576",
          "p50FileSize": "81576",
          "p75FileSize": "81576"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         1,
         "2026-01-23T09:54:32.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         0,
         "WriteSerializable",
         false,
         {
          "numFiles": "600",
          "numOutputBytes": "1650083",
          "numOutputRows": "300000"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         0,
         "2026-01-23T09:52:33.000Z",
         "252167878869526",
         "alexandre.bergere@datalex.io",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[\"ingest_date\"]",
          "properties": "{\"delta.parquet.compression.codec\":\"zstd\",\"delta.enableDeletionVectors\":\"true\"}",
          "statsOnLoad": "true"
         },
         null,
         [
          "2491241394162189"
         ],
         "0123-095152-mnd9q50q-v2n",
         null,
         "WriteSerializable",
         false,
         {
          "numDeletionVectorsRemoved": "0",
          "numFiles": "1",
          "numOutputBytes": "17337",
          "numOutputRows": "6000",
          "numRemovedBytes": "0",
          "numRemovedFiles": "0"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "before = spark.sql(f\"DESCRIBE DETAIL {full_name}\").collect()[0].asDict()\n",
    "print(\"BEFORE OPTIMIZE - numFiles:\", before[\"numFiles\"], \"sizeMB:\", round(before[\"sizeInBytes\"]/(1024*1024), 2))\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    OPTIMIZE {full_name}\n",
    "    WHERE ingest_date >= date_sub(current_date(), 2)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "after = spark.sql(f\"DESCRIBE DETAIL {full_name}\").collect()[0].asDict()\n",
    "print(\"AFTER OPTIMIZE  - numFiles:\", after[\"numFiles\"], \"sizeMB:\", round(after[\"sizeInBytes\"]/(1024*1024), 2))\n",
    "\n",
    "display(spark.sql(f\"DESCRIBE HISTORY {full_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02d89576-09eb-4ea4-b6da-9bd1f0c5f8f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5) Activer le CDF + faire une mise à jour + une insertion + lire les changements\n",
    "\n",
    "Le Change Data Feed (CDF) permet de lire uniquement les lignes modifiées entre deux versions.\n",
    "\n",
    "On va :\n",
    "- activer le CDF\n",
    "- noter la version `v_before`\n",
    "- faire un UPDATE + un INSERT\n",
    "- noter `v_after`\n",
    "- lire les changements via `table_changes(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "029536b1-e6e6-4621-a0dc-0904c845f9e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version before changes: 6\nroot\n |-- sensor_id: long (nullable = false)\n |-- humidity: double (nullable = true)\n |-- parcel: string (nullable = true)\n |-- ingest_date: date (nullable = false)\n\nVersion after changes: 8\nInserted sensor_id: 9162485\n"
     ]
    }
   ],
   "source": [
    "# Version avant modifications\n",
    "v_before = spark.sql(f\"DESCRIBE HISTORY {full_name} LIMIT 1\").collect()[0][\"version\"]\n",
    "print(\"Version before changes:\", v_before)\n",
    "\n",
    "# UPDATE (sur un capteur existant)\n",
    "spark.sql(f\"UPDATE {full_name} SET humidity = humidity + 1 WHERE sensor_id = 1000\")\n",
    "\n",
    "# INSERT (nouveau capteur) — version robuste: cast explicite\n",
    "new_id = int(time.time()) % 10_000_000\n",
    "\n",
    "sample = spark.table(full_name).orderBy(F.rand()).limit(1)\n",
    "\n",
    "inserted = (\n",
    "    sample\n",
    "    .withColumn(\"sensor_id\", F.lit(new_id).cast(\"long\"))   # ✅ cast explicite\n",
    "    .withColumn(\"humidity\", F.col(\"humidity\").cast(\"double\"))  # ✅ safe\n",
    "    .withColumn(\"ingest_date\", F.current_date())\n",
    ")\n",
    "\n",
    "# (Optionnel) vérifier le schéma avant écriture\n",
    "inserted.printSchema()\n",
    "\n",
    "inserted.write.format(\"delta\").mode(\"append\").saveAsTable(full_name)\n",
    "\n",
    "# Version après modifications\n",
    "v_after = spark.sql(f\"DESCRIBE HISTORY {full_name} LIMIT 1\").collect()[0][\"version\"]\n",
    "print(\"Version after changes:\", v_after)\n",
    "print(\"Inserted sensor_id:\", new_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41aab9a0-edaf-4e21-bf76-1060d6184d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sensor_id</th><th>humidity</th><th>parcel</th><th>ingest_date</th><th>_change_type</th><th>_commit_version</th><th>_commit_timestamp</th></tr></thead><tbody><tr><td>1000</td><td>31.9</td><td>West-2</td><td>2026-01-24</td><td>update_postimage</td><td>6</td><td>2026-01-23T09:58:56.000Z</td></tr><tr><td>1000</td><td>30.9</td><td>West-2</td><td>2026-01-23</td><td>update_preimage</td><td>6</td><td>2026-01-23T09:58:56.000Z</td></tr><tr><td>1000</td><td>30.9</td><td>West-2</td><td>2026-01-24</td><td>update_preimage</td><td>6</td><td>2026-01-23T09:58:56.000Z</td></tr><tr><td>1000</td><td>31.9</td><td>West-2</td><td>2026-01-23</td><td>update_postimage</td><td>6</td><td>2026-01-23T09:58:56.000Z</td></tr><tr><td>1000</td><td>32.9</td><td>West-2</td><td>2026-01-24</td><td>update_postimage</td><td>7</td><td>2026-01-23T10:01:25.000Z</td></tr><tr><td>1000</td><td>32.9</td><td>West-2</td><td>2026-01-23</td><td>update_postimage</td><td>7</td><td>2026-01-23T10:01:25.000Z</td></tr><tr><td>1000</td><td>31.9</td><td>West-2</td><td>2026-01-23</td><td>update_preimage</td><td>7</td><td>2026-01-23T10:01:25.000Z</td></tr><tr><td>1000</td><td>31.9</td><td>West-2</td><td>2026-01-24</td><td>update_preimage</td><td>7</td><td>2026-01-23T10:01:25.000Z</td></tr><tr><td>9162485</td><td>38.3</td><td>North-2</td><td>2026-01-23</td><td>insert</td><td>8</td><td>2026-01-23T10:01:27.000Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1000,
         31.9,
         "West-2",
         "2026-01-24",
         "update_postimage",
         6,
         "2026-01-23T09:58:56.000Z"
        ],
        [
         1000,
         30.9,
         "West-2",
         "2026-01-23",
         "update_preimage",
         6,
         "2026-01-23T09:58:56.000Z"
        ],
        [
         1000,
         30.9,
         "West-2",
         "2026-01-24",
         "update_preimage",
         6,
         "2026-01-23T09:58:56.000Z"
        ],
        [
         1000,
         31.9,
         "West-2",
         "2026-01-23",
         "update_postimage",
         6,
         "2026-01-23T09:58:56.000Z"
        ],
        [
         1000,
         32.9,
         "West-2",
         "2026-01-24",
         "update_postimage",
         7,
         "2026-01-23T10:01:25.000Z"
        ],
        [
         1000,
         32.9,
         "West-2",
         "2026-01-23",
         "update_postimage",
         7,
         "2026-01-23T10:01:25.000Z"
        ],
        [
         1000,
         31.9,
         "West-2",
         "2026-01-23",
         "update_preimage",
         7,
         "2026-01-23T10:01:25.000Z"
        ],
        [
         1000,
         31.9,
         "West-2",
         "2026-01-24",
         "update_preimage",
         7,
         "2026-01-23T10:01:25.000Z"
        ],
        [
         9162485,
         38.3,
         "North-2",
         "2026-01-23",
         "insert",
         8,
         "2026-01-23T10:01:27.000Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sensor_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "parcel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "_change_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_commit_version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "_commit_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT *\n",
    "        FROM table_changes('{full_name}', {v_before}, {v_after})\n",
    "        ORDER BY _commit_version, _commit_timestamp\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d15234c6-e5ab-494a-98c1-b26bf5d37260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6) Time Travel (lecture d’une version passée)\n",
    "\n",
    "On relit la version 0 (état initial de la table) pour comparer avec l’état actuel.\n",
    "\n",
    "**À observer :**\n",
    "- la version 0 ne contient pas les ajouts / changements récents\n",
    "- utile pour audit, debug et reproductibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc864d5-b993-494d-8789-a2d4882e3eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sensor_id</th><th>humidity</th><th>parcel</th><th>ingest_date</th></tr></thead><tbody><tr><td>1000</td><td>30.9</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1001</td><td>35.0</td><td>West-1</td><td>2026-01-23</td></tr><tr><td>1002</td><td>47.5</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1003</td><td>56.2</td><td>East-2</td><td>2026-01-23</td></tr><tr><td>1004</td><td>54.2</td><td>North-1</td><td>2026-01-23</td></tr><tr><td>1005</td><td>43.5</td><td>South-1</td><td>2026-01-23</td></tr><tr><td>1006</td><td>36.6</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1007</td><td>56.6</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1008</td><td>55.1</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1009</td><td>31.0</td><td>South-2</td><td>2026-01-23</td></tr><tr><td>1010</td><td>40.1</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1011</td><td>51.1</td><td>West-2</td><td>2026-01-23</td></tr><tr><td>1012</td><td>45.9</td><td>South-1</td><td>2026-01-23</td></tr><tr><td>1013</td><td>56.5</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1014</td><td>50.1</td><td>West-1</td><td>2026-01-23</td></tr><tr><td>1015</td><td>59.3</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1016</td><td>57.6</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1017</td><td>33.7</td><td>West-1</td><td>2026-01-23</td></tr><tr><td>1018</td><td>59.1</td><td>East-1</td><td>2026-01-23</td></tr><tr><td>1019</td><td>33.4</td><td>East-2</td><td>2026-01-23</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1000,
         30.9,
         "West-2",
         "2026-01-23"
        ],
        [
         1001,
         35.0,
         "West-1",
         "2026-01-23"
        ],
        [
         1002,
         47.5,
         "East-1",
         "2026-01-23"
        ],
        [
         1003,
         56.2,
         "East-2",
         "2026-01-23"
        ],
        [
         1004,
         54.2,
         "North-1",
         "2026-01-23"
        ],
        [
         1005,
         43.5,
         "South-1",
         "2026-01-23"
        ],
        [
         1006,
         36.6,
         "East-1",
         "2026-01-23"
        ],
        [
         1007,
         56.6,
         "West-2",
         "2026-01-23"
        ],
        [
         1008,
         55.1,
         "East-1",
         "2026-01-23"
        ],
        [
         1009,
         31.0,
         "South-2",
         "2026-01-23"
        ],
        [
         1010,
         40.1,
         "West-2",
         "2026-01-23"
        ],
        [
         1011,
         51.1,
         "West-2",
         "2026-01-23"
        ],
        [
         1012,
         45.9,
         "South-1",
         "2026-01-23"
        ],
        [
         1013,
         56.5,
         "East-1",
         "2026-01-23"
        ],
        [
         1014,
         50.1,
         "West-1",
         "2026-01-23"
        ],
        [
         1015,
         59.3,
         "East-1",
         "2026-01-23"
        ],
        [
         1016,
         57.6,
         "East-1",
         "2026-01-23"
        ],
        [
         1017,
         33.7,
         "West-1",
         "2026-01-23"
        ],
        [
         1018,
         59.1,
         "East-1",
         "2026-01-23"
        ],
        [
         1019,
         33.4,
         "East-2",
         "2026-01-23"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sensor_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "parcel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sensor_id</th><th>humidity</th><th>parcel</th><th>ingest_date</th></tr></thead><tbody><tr><td>1171</td><td>33.2</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>1371</td><td>32.5</td><td>South-2</td><td>2026-01-24</td></tr><tr><td>1571</td><td>50.1</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>1771</td><td>44.0</td><td>West-2</td><td>2026-01-24</td></tr><tr><td>1971</td><td>44.6</td><td>East-1</td><td>2026-01-24</td></tr><tr><td>2171</td><td>52.9</td><td>West-1</td><td>2026-01-24</td></tr><tr><td>2371</td><td>37.6</td><td>West-2</td><td>2026-01-24</td></tr><tr><td>2571</td><td>45.3</td><td>East-2</td><td>2026-01-24</td></tr><tr><td>2771</td><td>40.5</td><td>South-1</td><td>2026-01-24</td></tr><tr><td>2971</td><td>46.8</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>3171</td><td>47.4</td><td>West-1</td><td>2026-01-24</td></tr><tr><td>3371</td><td>59.6</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>3571</td><td>50.3</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>3771</td><td>33.2</td><td>East-1</td><td>2026-01-24</td></tr><tr><td>3971</td><td>36.5</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>4171</td><td>38.1</td><td>West-1</td><td>2026-01-24</td></tr><tr><td>4371</td><td>54.4</td><td>North-1</td><td>2026-01-24</td></tr><tr><td>4571</td><td>40.3</td><td>East-1</td><td>2026-01-24</td></tr><tr><td>4771</td><td>46.2</td><td>East-1</td><td>2026-01-24</td></tr><tr><td>4971</td><td>59.0</td><td>South-1</td><td>2026-01-24</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1171,
         33.2,
         "North-1",
         "2026-01-24"
        ],
        [
         1371,
         32.5,
         "South-2",
         "2026-01-24"
        ],
        [
         1571,
         50.1,
         "North-1",
         "2026-01-24"
        ],
        [
         1771,
         44.0,
         "West-2",
         "2026-01-24"
        ],
        [
         1971,
         44.6,
         "East-1",
         "2026-01-24"
        ],
        [
         2171,
         52.9,
         "West-1",
         "2026-01-24"
        ],
        [
         2371,
         37.6,
         "West-2",
         "2026-01-24"
        ],
        [
         2571,
         45.3,
         "East-2",
         "2026-01-24"
        ],
        [
         2771,
         40.5,
         "South-1",
         "2026-01-24"
        ],
        [
         2971,
         46.8,
         "North-1",
         "2026-01-24"
        ],
        [
         3171,
         47.4,
         "West-1",
         "2026-01-24"
        ],
        [
         3371,
         59.6,
         "North-1",
         "2026-01-24"
        ],
        [
         3571,
         50.3,
         "North-1",
         "2026-01-24"
        ],
        [
         3771,
         33.2,
         "East-1",
         "2026-01-24"
        ],
        [
         3971,
         36.5,
         "North-1",
         "2026-01-24"
        ],
        [
         4171,
         38.1,
         "West-1",
         "2026-01-24"
        ],
        [
         4371,
         54.4,
         "North-1",
         "2026-01-24"
        ],
        [
         4571,
         40.3,
         "East-1",
         "2026-01-24"
        ],
        [
         4771,
         46.2,
         "East-1",
         "2026-01-24"
        ],
        [
         4971,
         59.0,
         "South-1",
         "2026-01-24"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sensor_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "parcel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql(f\"SELECT * FROM {full_name} VERSION AS OF 0 LIMIT 20\"))\n",
    "display(spark.table(full_name).limit(20))  # version courante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ac769f-71e9-48a1-9f70-26a4977f4f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7) VACUUM avec une rétention courte (24h)\n",
    "\n",
    "Sur certains environnements (ex. Databricks Free Edition), il n’est pas possible de désactiver le “retention check”\n",
    "via une configuration Spark globale.\n",
    "\n",
    "On configure donc la rétention **au niveau de la table Delta** :\n",
    "- `delta.deletedFileRetentionDuration` : durée de conservation des fichiers de données supprimés\n",
    "- `delta.logRetentionDuration` : durée de conservation des fichiers de logs Delta\n",
    "\n",
    "Puis on lance `VACUUM`.\n",
    "\n",
    "⚠️ Attention : réduire la rétention limite le time travel sur des versions anciennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efcbe86-be5d-4603-a723-da491dd2724d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>delta.deletedFileRetentionDuration</td><td>interval 24 hours</td></tr><tr><td>delta.enableChangeDataFeed</td><td>true</td></tr><tr><td>delta.enableDeletionVectors</td><td>true</td></tr><tr><td>delta.feature.appendOnly</td><td>supported</td></tr><tr><td>delta.feature.changeDataFeed</td><td>supported</td></tr><tr><td>delta.feature.deletionVectors</td><td>supported</td></tr><tr><td>delta.feature.invariants</td><td>supported</td></tr><tr><td>delta.logRetentionDuration</td><td>interval 24 hours</td></tr><tr><td>delta.minReaderVersion</td><td>3</td></tr><tr><td>delta.minWriterVersion</td><td>7</td></tr><tr><td>delta.parquet.compression.codec</td><td>zstd</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta.deletedFileRetentionDuration",
         "interval 24 hours"
        ],
        [
         "delta.enableChangeDataFeed",
         "true"
        ],
        [
         "delta.enableDeletionVectors",
         "true"
        ],
        [
         "delta.feature.appendOnly",
         "supported"
        ],
        [
         "delta.feature.changeDataFeed",
         "supported"
        ],
        [
         "delta.feature.deletionVectors",
         "supported"
        ],
        [
         "delta.feature.invariants",
         "supported"
        ],
        [
         "delta.logRetentionDuration",
         "interval 24 hours"
        ],
        [
         "delta.minReaderVersion",
         "3"
        ],
        [
         "delta.minWriterVersion",
         "7"
        ],
        [
         "delta.parquet.compression.codec",
         "zstd"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Configurer la rétention au niveau de la table (24h)\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {full_name}\n",
    "SET TBLPROPERTIES (\n",
    "  delta.deletedFileRetentionDuration = 'interval 24 hours',\n",
    "  delta.logRetentionDuration = 'interval 24 hours'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Vérifier que les propriétés sont bien prises en compte\n",
    "display(spark.sql(f\"SHOW TBLPROPERTIES {full_name}\"))\n",
    "\n",
    "# 2) Lancer VACUUM (24h)\n",
    "spark.sql(f\"VACUUM {full_name} RETAIN 24 HOURS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9643347a-4249-427f-acdb-80668bbccb6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion (3–5 phrases)\n",
    "\n",
    "- Après plusieurs écritures, la table est fragmentée (numFiles augmente).\n",
    "- OPTIMIZE compacte les fichiers : numFiles diminue et les lectures deviennent plus efficaces.\n",
    "- Le CDF permet d’extraire uniquement les changements entre versions (utile pour CDC / pipelines incrémentaux).\n",
    "- Time Travel permet de relire un état passé de la table (audit/debug).\n",
    "- VACUUM supprime les fichiers obsolètes après rétention (utile pour maîtriser les coûts, mais attention à l’impact sur time travel)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7489151024973469,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "oc-lakehouse-correction-p2c5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}